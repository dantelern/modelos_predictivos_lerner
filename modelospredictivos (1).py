# -*- coding: utf-8 -*-
"""ModelosPredictivos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-2rIudY7XmgqB-SIrPFMi5nFI_S2UdJH
"""

# importo las librerias que necesito

import sklearn
import numpy as np
import pandas as pd
import seaborn
import matplotlib.pyplot as plt

#como shuffleamos y recortamos la data
#data_shuffled = data.sample(frac=1, random_state=42)
#rain_data = data_shuffled[data_shuffled['Precip Type'] == 'rain'][:2500]
#snow_data = data_shuffled[data_shuffled['Precip Type'] == 'snow'][:2500]
#final_data = pd.concat([rain_data, snow_data])
#final_data = pd.concat([rain_data, snow_data])
#final_data.to_csv('shuffled_data_with_rain_and_snow.csv', index=False)

# df1 = pd.read_csv('/content/weatherHistory.csv')
# shuffled_df = df1.sample(frac=1).reset_index(drop=True)

# hago archivo con los datos mezclados para usar en todo el trabajo

# path = '/content/shuffled_data_with_rain_and_snow.csv'
# shuffled_df.to_csv(path, index=False)

df = pd.read_csv('/content/shuffled_data_with_rain_and_snow.csv')

# borro columnas

columnas_a_borrar = ['Formatted Date', 'Loud Cover', 'Daily Summary']
df.drop(columns=columnas_a_borrar, inplace=True)

# mejoro el estilo del dataframe para mostrarlo con los graficos

styled_df = df.style \
   .set_properties(**{'background-color': 'lightyellow', 'color': 'black'}) \
   .highlight_null(color='red') \
   .set_caption('DataFrame') \
   .format({'Temperature (C)': '{:.2f}'})

df

"""decision tree"""

# importo las librerias que necesito y leo el archivo

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.tree import plot_tree
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

df = pd.read_csv('/content/shuffled_data_with_rain_and_snow.csv')

# utilizo la función LabelEncoder para transformar los datos que necesito

label_encoder = LabelEncoder()

df['Summary'] = label_encoder.fit_transform(df['Summary'])
df['Precip Type'] = label_encoder.fit_transform(df['Precip Type'])

# defino mis features y targets

X = df[['Humidity', 'Wind Speed (km/h)', 'Pressure (millibars)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Summary', 'Precip Type']]
y = df[['Temperature (C)']]

# divido los datos por train y test, con hiperparámetros que sirvan para predecir otros datos

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
model = DecisionTreeRegressor(max_depth=6, random_state=1, min_samples_leaf=32, min_samples_split=8)

# meto los datos de entrenamiento en el modelo

model.fit(X_train, y_train)

plt.figure(figsize=(10, 6))
plot_tree(model, filled=True, feature_names=['Humidity', 'Wind Speed (km/h)', 'Pressure (millibars)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Summary', 'Precip Type'])

# aplico la cross validation para ver como funciona

scores = cross_val_score(model, X_train, y_train, cv=5)
print('El promedio es de', scores.mean())

"""linear regression"""

#importo las ibrerias que necesito
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from sklearn import linear_model
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import cross_val_score


label_encoder = LabelEncoder()

#agarro los datos que necesito
data = pd.read_csv('shuffled_data_with_rain_and_snow.csv')
data = data.drop(columns=['Loud Cover', 'Daily Summary', 'Formatted Date', 'Apparent Temperature (C)'], axis=1)


#uso el label encoder para los valores no numericos
data['Summary'] = label_encoder.fit_transform(data['Summary'])
data['Precip Type'] = label_encoder.fit_transform(data['Precip Type'])


#uso el one hot encoder
onehot_encoder = OneHotEncoder(sparse=False, drop='first')
summary_onehot = onehot_encoder.fit_transform(data[['Summary']])
precip_type_onehot = onehot_encoder.fit_transform(data[['Precip Type']])

#separo los datos
preX= data.drop('Temperature (C)', axis=1).values
X = data.drop(columns=['Temperature (C)'])
y = data['Temperature (C)']


#divido los datos en train y en test y ademas los escalo
y = np.array(y)
y = y.reshape(-1, 1)

scaler = StandardScaler()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)


X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


y_train_scaled = scaler.fit_transform(y_train)
y_test_scaled = scaler.transform(y_test)


# Creo mi modelo de regresión lineal con los parametros que creo convenientes
model = linear_model.LinearRegression(fit_intercept=True, copy_X=True)

# determino el cross validation con 5 que determina los dobleces que va  a hacer
cv_scores = cross_val_score(model, X_test, y_test, cv=5)

# meto ls datos del train
model.fit(X_train, y_train)

# hago las predicciones
y_pred = model.predict(X_test)

# Calcular el porcentaje de validacion r2 de sklearn
r2 = r2_score(y_test, y_pred)

# Calculate el porcentaje de validacion usando cross validation
mean_cv_r2 = cv_scores.mean()

print("Mean R2 Score from Cross-Validation:", mean_cv_r2)
print("R2 Score on Testing Data:", r2)

"""decision tree classifier"""

# importo las librerias necesarias
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# leo el archivo csv
df = pd.read_csv('/content/shuffled_data_with_rain_and_snow.csv')

# utilizo la función LabelEncoder para transformar los datos que necesito
label_encoder = LabelEncoder()

df['Summary'] = label_encoder.fit_transform(df['Summary'])
df['Precip Type'] = label_encoder.fit_transform(df['Precip Type'])

# defino mis features y targets

X = df[['Humidity', 'Wind Speed (km/h)', 'Pressure (millibars)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Summary']] # , 'Apparent Temperature (C)'
y = df[['Precip Type']]

# divido los datos por train y test, con hiperparámetros que sirvan para predecir otros datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)
clf = DecisionTreeClassifier(random_state=42, max_depth=6)

# entreno al modelo
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

# calculo la performance del arbol
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

plt.figure(figsize=(12, 6))

# Ploteo el arbol
plot_tree(clf, filled=True, feature_names=X.columns, class_names=['Snow', 'Rain'])
plt.show()

"""logistic regression"""

# importo las librerias
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
import numpy


df = pd.read_csv('/content/shuffled_data_with_rain_and_snow.csv')

# utilizo la función LabelEncoder para los datos no numericos
label_encoder = LabelEncoder()

df['Summary'] = label_encoder.fit_transform(df['Summary'])
df['Precip Type'] = label_encoder.fit_transform(df['Precip Type'])

# defino que voy a predecir y con que atributos

X = df[['Humidity', 'Wind Speed (km/h)', 'Pressure (millibars)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Summary']] # , 'Apparent Temperature (C)'
y = df[['Precip Type']]

# divido los datos por train y test, con hiperparámetros que sirvan para predecir otros datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Creando y entrenando el modelo

LRmodel = LogisticRegression()

LRmodel.fit(X_train, y_train)

#Prediciendo y midiendo el score resultante

y_prediction = LRmodel.predict(X_test)

LRmodel.score(X_test, y_test)

#Creando una Confusion Matrix

confusion_matrix = metrics.confusion_matrix(y_test, y_prediction)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])

#Mostrando la Confusion Matrix

cm_display.plot()
plt.show()

"""5) Para poder medir la performance de un árbol de decisión, lo ideal antes de utilizar el modelo para predecir es utilizar una validación cruzada que me permita cuantificar dicha performance y ajustar los distintos hiperparámetros que definen un modelo de árbol de decisión, como puede ser el número de decisiones que se llevan a cabo. De esta forma, podemos también comparar la performance respecto a otros modelos para evaluar cuál es más efectivo, midiendo ya sea el error de manera convencional o el error medio cuadrático.

b. Si quiero medir la performance de una regresión logística y ajustar sus hiperparámetros, una manera podría ser usando una “Confusion Matrix”, que es una matriz que me permite visualizar cuantos errores y cuantos aciertos hubo en el modelo. En cuanto al árbol de decisión, es posible plotear el árbol y determinar las salidas respecto a las variables del dataset, de manera que se cuenta con una mejor visualización de todos los hiperparámetros que componen al sistema. Sin embargo, si el fin es comparar ambos modelos, la Confusion Matrix aplicada a ambos resulta siendo la manera más fidedigna y clara de comparar a ambos

7.
**Validación cruzada de k-fold** (k-Fold Cross-Validation):

Ventajas:
* Facil de usar
* Buena prediccion
* Util para utilizar con pocos datos

Desventajas:
* Puede demorar mucho si son muchos datos
* No util para datos desequilibrados

**Validación cruzada Leave-One-Out (LOO):**

Ventajas:
* Estimacion precisa de la performance
* Prueba cada grupo de datos por separado

Desventajas:
* Muy lento si hay muchos datos

**Validación cruzada Leave-P-Out (LPO):**

Ventajas:
* Un intermedio entre LOO y k-fold en velocidad y presicion

Desventajas:
* Requiere ajustes de la cantidad de datos

**Validación cruzada estratificada:**

Ventajas:
* Util para clases desequilibradas

Desventajas:
* Puede ser más difícil de implementar correctamente.

**Validación cruzada en series temporales (Time Series Cross-Validation):**

Ventajas:
* Está diseñada para datos de series temporales, donde el orden de los datos es importante.

Desventajas:
* Puede ser compleja de implementar.
* No es ideal para datos no temporales.

**Validación cruzada estratificada por grupos:**

Ventajas:
*   Útil cuando los datos están agrupados en grupos y se quiere evitar que los mismos grupos aparezcan ambos en el test y en el train.

Desventajas:
*   Mas complejo de configurar
*   Puede requerir informacion extra

A la hora de elegir un método de validación cruzada hay que tener en cuenta el conjunto de datos y el problema que se quiera solucionar. No hay un tipo que sea el correcto para todas las situaciones, hay que saber qué método elegir en cada caso. Además no es el único criterio que se debe tener en cuenta para evaluar la performance de un modelo predictivo.

## **CONCLUSIÓN DEL TRABAJO**

Nos permitió indagar sobre como funcionan distintas formas de análisis de datos. Al tener que programar nuestras propias regresiones y árboles de decisiones, pudimos ver como funciona cada método de evaluación.
> Aprendimos sobre:
* la importancia de los hiperparámetros
* las diferencias en los procesos
* como prevenir overfitting/data leakage
* interpretar el dataset a partir de gráficos

## **BONUS**

Elegimos usar Randomized Search como hiperparametro en una regresion lineal, los parametros obtenidos los usamos luego en a regresion lineal hecha al principio.
"""

#importo las ibrerias que necesito
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from sklearn import linear_model
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RandomizedSearchCV


label_encoder = LabelEncoder()

#agarro los datos que necesito
data = pd.read_csv('shuffled_data_with_rain_and_snow.csv')
data = data.drop(columns=['Loud Cover', 'Daily Summary', 'Formatted Date', 'Apparent Temperature (C)'], axis=1)


#uso el label encoder para los valores no numericos
data['Summary'] = label_encoder.fit_transform(data['Summary'])
data['Precip Type'] = label_encoder.fit_transform(data['Precip Type'])


#uso el one hot encoder
onehot_encoder = OneHotEncoder(sparse=False, drop='first')
summary_onehot = onehot_encoder.fit_transform(data[['Summary']])
precip_type_onehot = onehot_encoder.fit_transform(data[['Precip Type']])

#separo los datos
preX= data.drop('Temperature (C)', axis=1).values
X = data.drop(columns=['Temperature (C)'])
y = data['Temperature (C)']


#divido los datos en train y en test y ademas los escalo
y = np.array(y)
y = y.reshape(-1, 1)

scaler = StandardScaler()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)


X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


y_train_scaled = scaler.fit_transform(y_train)
y_test_scaled = scaler.transform(y_test)


# crear el modelo
model = linear_model.LinearRegression()

# definir los paramtros con los que va a probar el RandomizedSearch
param_grid = {
    'fit_intercept': [True, False],
    'copy_X': [True, False]
}

# Crear un objeto de RandomizedSearch
random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=10, cv=5, scoring='r2', random_state=42)

# insertar mis datos en el random search
random_search.fit(X_train, y_train)

# conseguir s mejores parametros
best_model = random_search.best_estimator_

# hacer predicciones con el mejor modelo
y_pred = best_model.predict(X_test)

# calcular el porcentaje usando r2 y printear los valores
r2 = r2_score(y_test, y_pred)
print("Best Hyperparameters:", random_search.best_params_)
print("R2 Score on Testing Data with Tuned Hyperparameters:", r2)

"""Para el segundo bonus elegimos el support vector machine que se puede utilizar tanto para tareas de clasificación como de regresión. Nosotros lo utilizamos en este caso como clasificador"""

# importo las librerias
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
from sklearn import svm
from sklearn.metrics import accuracy_score, classification_report


df = pd.read_csv('/content/shuffled_data_with_rain_and_snow.csv')

# utilizo la función LabelEncoder para los datos no numericos
label_encoder = LabelEncoder()

df['Summary'] = label_encoder.fit_transform(df['Summary'])
df['Precip Type'] = label_encoder.fit_transform(df['Precip Type'])

# defino que voy a predecir y con que atributos

X = df[['Humidity', 'Wind Speed (km/h)', 'Pressure (millibars)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Summary']] # , 'Apparent Temperature (C)'
y = df[['Precip Type']]

# divido los datos por train y test, con hiperparámetros que sirvan para predecir otros datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Crear un modelo svm y asignarle un kernel que se define segun como se separan los datos durante la clasificacin binaria sineod en nuestro cais el conveniente linear
clf = svm.SVC(kernel='linear')
clf.fit(X_train, y_train)

# Predict en training y testing
y_train_pred = clf.predict(X_train)
train_accuracy = accuracy_score(y_train, y_train_pred)

y_pred = clf.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)

# generar el classification report
report = classification_report(y_test, y_pred)

# Printear los valores obtenidos
print(f"Training Accuracy: {train_accuracy}")
print(f"Testing Accuracy: {test_accuracy}")
print(f"Classification Report:\n{report}")